---
title: "p8105_hw2_zf2352"
author: "Zhenkun Fang"
date: "2024-09-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(dplyr)
library(tidyr)
library(haven)
```

# Probelm 1

```{r, show_col_types = FALSE}
nyc_subway = 
  read_csv("/Users/rubp/Desktop/Data Sci 1/Week4/HW2/p8105_hw2_zf2352/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
           na = c("NA", ".", "")) %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, 
         route1, route2, route3, route4, route5, 
         entry, vending, entrance_type, ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))

view(nyc_subway)
```

The dataset contains subway line information, station names, latitude and longitude, the routes served, whether thereâ€™s an entrance, vending availability, entrance type (stair or elevator), and ADA compliance.

My data cleaning steps include converting all missing values to "NA", converting column names to a consistent format: lower case, replacing spaces and special characters with underscores, retaining the variables that are useful for later, and converting entry variable from character to logical variable.

The resulting dataset has 1868 rows and 13 columns.

These data is tidy except the routes served. It would be better to have a variable "route(s)" with one row for each combination of entrance and route.

Answer the following questions using these data:
1. How many distinct stations are there? Note that stations are identified both by name and by line (e.g. 125th St 8th Avenue; 125st Broadway; 125st Lenox); the distinct function may be useful here.

```{r}
distinct_stations = nyc_subway %>%
  distinct(station_name, line)

num_distinct_stations = nrow(distinct_stations)

num_distinct_stations
```

- There are 465 distinct stations.

2. How many stations are ADA compliant?
```{r}
ada_complicant = nyc_subway %>% 
  filter(ada == "TRUE")

num_adacomplicant = nrow(ada_complicant)

num_adacomplicant
```

- There are 468 stations are ADA compliant.

3. What proportion of station entrances / exits without vending allow entrance?

```{r}
allow_entrance = nyc_subway %>% 
  filter(vending == "NO") %>% 
  filter(entry == "YES")

num_allow_entrance = nrow(allow_entrance)

proportion = nrow(num_allow_entrance)/nrow(nyc_subway)

proportion
```

- The proportion is 0.

```{r, reformat}
reformat_nyc_subway = nyc_subway %>% 
  pivot_longer(
    cols = route1:route5,
    names_to = "route_number",
    values_to = "route_name",
    values_drop_na = TRUE
  )

reformat_nyc_subway
```

```{r}
Atrain = reformat_nyc_subway %>% 
  filter(route_name == "A")

num_Atrain = nrow(Atrain)

num_Atrain

Atrain_ada = Atrain %>% 
  filter(ada == TRUE)

num_Atrain_ada = nrow(Atrain_ada)

num_Atrain_ada
```

There are 273 distinct stations serve the A train. Of the stations that serve the A train, 107 stations are ADA compliant.

# Problem 2
```{r}
mrtrash_wheel = read_excel("/Users/rubp/Desktop/Data Sci 1/Week4/HW2/p8105_hw2_zf2352/202309_Trash Wheel_Collection Data.xlsx",
                         na = c("NA", ".", "")) %>% 
  janitor::clean_names() %>%
  select(-c(15, 16)) %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = as.integer(round(sports_balls)))
```

```{r}
mrtrash_wheel = mrtrash_wheel %>% 
  mutate(person = "mr_trash_wheel")

proftrash_wheel = read_excel("/Users/rubp/Desktop/Data Sci 1/Week4/HW2/p8105_hw2_zf2352/202309_Trash Wheel_Collection Data.xlsx", 
                             sheet = 2,
                             na = c("NA", ".", "")) %>% 
  janitor::clean_names() %>%
  filter(!is.na(dumpster)) %>% 
  mutate(person = "prof_trash_wheel")

gwynnda_trash_wheel = read_excel("/Users/rubp/Desktop/Data Sci 1/Week4/HW2/p8105_hw2_zf2352/202309_Trash Wheel_Collection Data.xlsx", 
                             sheet = 4,
                             na = c("NA", ".", "")) %>% 
  janitor::clean_names() %>%
  filter(!is.na(dumpster)) %>% 
  mutate(person = "gwynnda_trash_wheel")
```

```{r combine dataset}

```

